{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('tobigs14-mnist-competition/train_df.csv')\n",
    "test_data = pd.read_csv('tobigs14-mnist-competition/test_df.csv')\n",
    "sample_submission = pd.read_csv(\"tobigs14-mnist-competition/sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0      7       0       0       0       0       0       0       0       0   \n",
       "1      8       0       0       0       0       0       0       0       0   \n",
       "2      7       0       0       0       0       0       0       0       0   \n",
       "3      6       0       0       0       0       0       0       0       0   \n",
       "4      5       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0       0  ...         0         0         0         0         0         0   \n",
       "1       0  ...         0         0         0         0         0         0   \n",
       "2       0  ...         0         0         0         0         0         0   \n",
       "3       0  ...         0         0         0         0         0         0   \n",
       "4       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "2         0         0         0         0  \n",
       "3         0         0         0         0  \n",
       "4         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 어떤 자료인지 보자\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_data.drop('label',axis = 1).values\n",
    "y_train = train_data['label'].values\n",
    "\n",
    "X_test = test_data.iloc[:,1:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((42000, 784), (42000,), (18000, 784))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 하나 출력해볼까!\n",
    "\n",
    "index = 0\n",
    "image = X_train[index].reshape(28,28)\n",
    "plt.imshow(image, 'gray')\n",
    "plt.title('label : {}'.format(y_train[index]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_size => 784\n",
      "image_width => 28\n",
      "image_height => 28\n"
     ]
    }
   ],
   "source": [
    "# 전체 784 pixel, 즉, 28*28 사이즈의 그림들임!\n",
    "\n",
    "image_size = X_train.shape[1]\n",
    "print ('image_size => {0}'.format(image_size))\n",
    "\n",
    "# in this case all images are square\n",
    "image_width = image_height = np.ceil(np.sqrt(image_size)).astype(np.uint8)\n",
    "\n",
    "print ('image_width => {0}\\nimage_height => {1}'.format(image_width,image_height))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum value after scaling: 1.0 \n",
      "minimum value after scaling: 0.0\n"
     ]
    }
   ],
   "source": [
    "# scaling\n",
    "\n",
    "X_train = X_train.astype(np.float)\n",
    "X_test = X_test.astype(np.float)\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "print('maximum value after scaling:', X_train.max(),\n",
    "      '\\nminimum value after scaling:' ,X_train.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33600, 784) (33600,)\n",
      "(8400, 784) (8400,)\n"
     ]
    }
   ],
   "source": [
    "# train test split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2)\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tensorflow keras model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Dropout\n",
    "* overfitting을 방지하기 위한 방법 중 하나\n",
    "* 각 계층에서 무작위로 선택된 뉴런의 연결을 끊으며 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "336/336 [==============================] - 6s 19ms/step - loss: 0.2110 - accuracy: 0.9390\n",
      "Epoch 2/5\n",
      "336/336 [==============================] - 5s 16ms/step - loss: 0.0719 - accuracy: 0.9781\n",
      "Epoch 3/5\n",
      "336/336 [==============================] - 8s 24ms/step - loss: 0.0466 - accuracy: 0.9855ETA: 1s\n",
      "Epoch 4/5\n",
      "336/336 [==============================] - 7s 22ms/step - loss: 0.0330 - accuracy: 0.9899\n",
      "Epoch 5/5\n",
      "336/336 [==============================] - 6s 18ms/step - loss: 0.0265 - accuracy: 0.9917 0s - loss: 0.0265 - accuracy: 0.99\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 0.0529 - accuracy: 0.9849\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.05288335308432579, 0.9848809242248535]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(512, activation='relu'),\n",
    "    keras.layers.Dropout(0.3),\n",
    "    keras.layers.Dense(512, activation='relu'),\n",
    "    keras.layers.Dropout(0.2), \n",
    "    # dropout 대신 keras.layers.BatchNormalization() 이용 가능\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, epochs=5, batch_size=100)\n",
    "model.evaluate(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "168/168 [==============================] - 5s 29ms/step - loss: 0.2621 - accuracy: 0.9256\n",
      "Epoch 2/5\n",
      "168/168 [==============================] - 5s 32ms/step - loss: 0.0851 - accuracy: 0.9738\n",
      "Epoch 3/5\n",
      "168/168 [==============================] - 5s 29ms/step - loss: 0.0539 - accuracy: 0.9839\n",
      "Epoch 4/5\n",
      "168/168 [==============================] - 5s 30ms/step - loss: 0.0376 - accuracy: 0.9886\n",
      "Epoch 5/5\n",
      "168/168 [==============================] - 5s 29ms/step - loss: 0.0266 - accuracy: 0.9918 0s - loss: 0.0263 - accuracy: 0.\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 0.0453 - accuracy: 0.9876\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.04534053057432175, 0.9876190423965454]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#barch_size만 일단 변화시켜보았다.  -- 성능이 조금 좋아진것을 확인할 수 있다. \n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(512, activation='relu'),\n",
    "    keras.layers.Dropout(0.3),\n",
    "    keras.layers.Dense(512, activation='relu'),\n",
    "    keras.layers.Dropout(0.2), \n",
    "    # dropout 대신 keras.layers.BatchNormalization() 이용 가능\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, epochs=5, batch_size=200) \n",
    "model.evaluate(X_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Weight Initialization\n",
    "* 기울기가 소실되는 문제를 어느정도 방지하기 위해 가중치 초기화 체계를 변경하여 모델 학습을 향상시킬 수 있다. \n",
    "* activation함수에 따라 효율적인 가중치초기화 함수를 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Weight Initialization - Xavier(Glorot)\n",
    "* ReLu 등장 후에 Glorot이 2010년에 제안한 방법으로 vanshing gradient 문제를 해결하기 위해 만들어졌다고 한다\n",
    "* input 과 output의 뉴런수에 기반하여 초기화의 스케일을 정함\n",
    "* Normal distribution -- sqrt(2. / (in + out))\n",
    "* Uniform distribution -- x = sqrt( σ / (in + out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "168/168 [==============================] - 5s 29ms/step - loss: 0.2658 - accuracy: 0.9249\n",
      "Epoch 2/8\n",
      "168/168 [==============================] - 5s 28ms/step - loss: 0.0862 - accuracy: 0.9741\n",
      "Epoch 3/8\n",
      "168/168 [==============================] - 5s 30ms/step - loss: 0.0563 - accuracy: 0.9822\n",
      "Epoch 4/8\n",
      "168/168 [==============================] - 5s 28ms/step - loss: 0.0395 - accuracy: 0.9875\n",
      "Epoch 5/8\n",
      "168/168 [==============================] - 5s 33ms/step - loss: 0.0296 - accuracy: 0.9910\n",
      "Epoch 6/8\n",
      "168/168 [==============================] - 4s 26ms/step - loss: 0.0234 - accuracy: 0.9925\n",
      "Epoch 7/8\n",
      "168/168 [==============================] - 5s 33ms/step - loss: 0.0200 - accuracy: 0.9937\n",
      "Epoch 8/8\n",
      "168/168 [==============================] - 4s 26ms/step - loss: 0.0151 - accuracy: 0.9950\n",
      "263/263 [==============================] - 2s 6ms/step - loss: 0.0446 - accuracy: 0.9871: 0s - loss: 0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.04459522292017937, 0.9871428608894348]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#활성화함수 relu, 가중치초기화는 glorot_normal로하여 해보았다. -- 성능이 뛰어나게 좋아지진 못했다.\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(512, input_shape = (784, ),activation = 'relu', kernel_initializer='glorot_normal'), \n",
    "    keras.layers.Dropout(0.3),\n",
    "    keras.layers.Dense(512,activation = 'relu',kernel_initializer='glorot_normal'),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(10, activation = 'softmax', kernel_initializer='glorot_normal')                         \n",
    "])\n",
    "    \n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, epochs=8, batch_size=200) \n",
    "#에콕을 10개로주었을떄 8개째에서 정확도가 계속비슷하거나 떨어지는 현상이 보여서 8개로 줄여서 해보았다. \n",
    "model.evaluate(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "168/168 [==============================] - 5s 29ms/step - loss: 0.2628 - accuracy: 0.9253\n",
      "Epoch 2/8\n",
      "168/168 [==============================] - 5s 28ms/step - loss: 0.0844 - accuracy: 0.9744\n",
      "Epoch 3/8\n",
      "168/168 [==============================] - 5s 30ms/step - loss: 0.0572 - accuracy: 0.9830\n",
      "Epoch 4/8\n",
      "168/168 [==============================] - 5s 28ms/step - loss: 0.0417 - accuracy: 0.9869\n",
      "Epoch 5/8\n",
      "168/168 [==============================] - 5s 31ms/step - loss: 0.0295 - accuracy: 0.9904\n",
      "Epoch 6/8\n",
      "168/168 [==============================] - 5s 27ms/step - loss: 0.0233 - accuracy: 0.9924\n",
      "Epoch 7/8\n",
      "168/168 [==============================] - 5s 31ms/step - loss: 0.0170 - accuracy: 0.9949\n",
      "Epoch 8/8\n",
      "168/168 [==============================] - 4s 26ms/step - loss: 0.0148 - accuracy: 0.9952\n",
      "263/263 [==============================] - ETA: 0s - loss: 0.0530 - accuracy: 0.98 - 1s 5ms/step - loss: 0.0525 - accuracy: 0.9861\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.05250084400177002, 0.9860714077949524]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#위의 코드에서 가중치 초기화 함수를 glorot_uniform으로 바꾸어보았다. -- uniform보다는 normal이 나은것같다\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(512, input_shape = (784, ),activation = 'relu', kernel_initializer='glorot_uniform'), \n",
    "    keras.layers.Dropout(0.3),\n",
    "    keras.layers.Dense(512,activation = 'relu',kernel_initializer='glorot_uniform'),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(10, activation = 'softmax', kernel_initializer='glorot_uniform')                         \n",
    "])\n",
    "    \n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, epochs=8, batch_size=200) \n",
    " \n",
    "model.evaluate(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "168/168 [==============================] - 5s 29ms/step - loss: 0.2235 - accuracy: 0.9340 \n",
      "Epoch 2/8\n",
      "168/168 [==============================] - 5s 29ms/step - loss: 0.1196 - accuracy: 0.9625\n",
      "Epoch 3/8\n",
      "168/168 [==============================] - 5s 29ms/step - loss: 0.0967 - accuracy: 0.9698\n",
      "Epoch 4/8\n",
      "168/168 [==============================] - 5s 29ms/step - loss: 0.0801 - accuracy: 0.9746\n",
      "Epoch 5/8\n",
      "168/168 [==============================] - 6s 35ms/step - loss: 0.0679 - accuracy: 0.9781\n",
      "Epoch 6/8\n",
      "168/168 [==============================] - 6s 35ms/step - loss: 0.0588 - accuracy: 0.9817\n",
      "Epoch 7/8\n",
      "168/168 [==============================] - 10s 58ms/step - loss: 0.0519 - accuracy: 0.9830\n",
      "Epoch 8/8\n",
      "168/168 [==============================] - 6s 34ms/step - loss: 0.0445 - accuracy: 0.9857\n",
      "263/263 [==============================] - 1s 6ms/step - loss: 0.0776 - accuracy: 0.9776\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.07761242985725403, 0.9776190519332886]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Xavier가 효율적이라는 활성화함수인 sigmoid와 tanh를 써보았는데 relu를했을떄보다 성능이 안좋았다. \n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(512, input_shape = (784, ),activation = 'tanh', kernel_initializer='glorot_normal'), \n",
    "    keras.layers.Dropout(0.3),\n",
    "    keras.layers.Dense(512,activation = 'tanh',kernel_initializer='glorot_normal'),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(10, activation = 'softmax', kernel_initializer='glorot_normal')                         \n",
    "])\n",
    "    \n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, epochs=8, batch_size=200) \n",
    "model.evaluate(X_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Weight Initialization - he\n",
    "* Glorot과 유사하지만 뉴런의 output_size를 고려하진 않는다\n",
    "* ReLu가 0 이하의 신호를 제거하기 때문에 분산을 유지한다는 의도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "168/168 [==============================] - 4s 25ms/step - loss: 0.2804 - accuracy: 0.9176\n",
      "Epoch 2/8\n",
      "168/168 [==============================] - 6s 34ms/step - loss: 0.0943 - accuracy: 0.9712\n",
      "Epoch 3/8\n",
      "168/168 [==============================] - 4s 26ms/step - loss: 0.0604 - accuracy: 0.9822\n",
      "Epoch 4/8\n",
      "168/168 [==============================] - 6s 33ms/step - loss: 0.0426 - accuracy: 0.9872\n",
      "Epoch 5/8\n",
      "168/168 [==============================] - 4s 27ms/step - loss: 0.0327 - accuracy: 0.9900\n",
      "Epoch 6/8\n",
      "168/168 [==============================] - 6s 33ms/step - loss: 0.0249 - accuracy: 0.9923\n",
      "Epoch 7/8\n",
      "168/168 [==============================] - 5s 28ms/step - loss: 0.0204 - accuracy: 0.9933\n",
      "Epoch 8/8\n",
      "168/168 [==============================] - 5s 32ms/step - loss: 0.0176 - accuracy: 0.9942\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 0.0434 - accuracy: 0.9876\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.04336514323949814, 0.9876190423965454]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#활성화함수 relu, 가중치초기화는 he_normal 사용. -- 성능이 뛰어나게 좋아지진 못했다.\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(512, input_shape = (784, ),activation = 'relu', kernel_initializer='he_normal'), \n",
    "    keras.layers.Dropout(0.3),\n",
    "    keras.layers.Dense(512,activation = 'relu',kernel_initializer='he_normal'),\n",
    "    keras.layers.Dropout(0.3),\n",
    "    keras.layers.Dense(10, activation = 'softmax', kernel_initializer='he_normal')                         \n",
    "])\n",
    "    \n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, epochs=8, batch_size=200) \n",
    " \n",
    "model.evaluate(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "168/168 [==============================] - 5s 27ms/step - loss: 0.2729 - accuracy: 0.9205\n",
      "Epoch 2/8\n",
      "168/168 [==============================] - 6s 33ms/step - loss: 0.0904 - accuracy: 0.9721\n",
      "Epoch 3/8\n",
      "168/168 [==============================] - 4s 26ms/step - loss: 0.0598 - accuracy: 0.9812\n",
      "Epoch 4/8\n",
      "168/168 [==============================] - 5s 32ms/step - loss: 0.0421 - accuracy: 0.9868\n",
      "Epoch 5/8\n",
      "168/168 [==============================] - 5s 27ms/step - loss: 0.0309 - accuracy: 0.9907\n",
      "Epoch 6/8\n",
      "168/168 [==============================] - 5s 32ms/step - loss: 0.0254 - accuracy: 0.9920\n",
      "Epoch 7/8\n",
      "168/168 [==============================] - 5s 28ms/step - loss: 0.0199 - accuracy: 0.9939\n",
      "Epoch 8/8\n",
      "168/168 [==============================] - 5s 30ms/step - loss: 0.0156 - accuracy: 0.9946\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 0.0440 - accuracy: 0.9881\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.04399489611387253, 0.988095223903656]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#위의 코드에서 가중치 초기화 함수를 he_uniform으로 바꾸어보았다. \n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(512, input_shape = (784, ),activation = 'relu', kernel_initializer='he_uniform'), \n",
    "    keras.layers.Dropout(0.3),\n",
    "    keras.layers.Dense(512,activation = 'relu',kernel_initializer='he_uniform'),\n",
    "    keras.layers.Dropout(0.3),\n",
    "    keras.layers.Dense(10, activation = 'softmax', kernel_initializer='he_uniform')                         \n",
    "])\n",
    "    \n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, epochs=8, batch_size=200) \n",
    " \n",
    "model.evaluate(X_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Batch Normalization\n",
    "* \"internal covariance shift\"문제를 방지하는 방법 중 하나이다\n",
    "* 미니 배치를 만들어서 정규화시킨다\n",
    "* 활성화함수가 들어가기 이전에 시행한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n",
      "168/168 [==============================] - 6s 35ms/step - loss: 0.1605 - accuracy: 0.9518\n",
      "Epoch 2/7\n",
      "168/168 [==============================] - 4s 27ms/step - loss: 0.0343 - accuracy: 0.9901\n",
      "Epoch 3/7\n",
      "168/168 [==============================] - 6s 34ms/step - loss: 0.0137 - accuracy: 0.9964\n",
      "Epoch 4/7\n",
      "168/168 [==============================] - 5s 27ms/step - loss: 0.0088 - accuracy: 0.9976\n",
      "Epoch 5/7\n",
      "168/168 [==============================] - 5s 31ms/step - loss: 0.0060 - accuracy: 0.9982\n",
      "Epoch 6/7\n",
      "168/168 [==============================] - 5s 30ms/step - loss: 0.0033 - accuracy: 0.9992\n",
      "Epoch 7/7\n",
      "168/168 [==============================] - 5s 30ms/step - loss: 0.0052 - accuracy: 0.9986\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 0.0516 - accuracy: 0.9861\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.05164211243391037, 0.9860714077949524]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#drop_out대신에 batchnomarlization을 사용해보았다. \n",
    " \n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(512, input_shape = (784, ),activation = 'relu', kernel_initializer='he_uniform'), \n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(512,activation = 'relu',kernel_initializer='he_uniform'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(10, activation = 'softmax', kernel_initializer='he_uniform')                         \n",
    "])\n",
    "    \n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, epochs=7, batch_size=200)  \n",
    "model.evaluate(X_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Optimization\n",
    "* 최적의 하이퍼파라미터 값 찾기\n",
    "* 가장 유명한 것 중 하나가 Adam (Adaptive Moment Estimation)이다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "168/168 [==============================] - 5s 32ms/step - loss: 0.3110 - accuracy: 0.9040\n",
      "Epoch 2/8\n",
      "168/168 [==============================] - 6s 35ms/step - loss: 0.1339 - accuracy: 0.9597\n",
      "Epoch 3/8\n",
      "168/168 [==============================] - 6s 33ms/step - loss: 0.1042 - accuracy: 0.9673\n",
      "Epoch 4/8\n",
      "168/168 [==============================] - 6s 33ms/step - loss: 0.0787 - accuracy: 0.9764\n",
      "Epoch 5/8\n",
      "168/168 [==============================] - 6s 33ms/step - loss: 0.0653 - accuracy: 0.9794\n",
      "Epoch 6/8\n",
      "168/168 [==============================] - 6s 34ms/step - loss: 0.0536 - accuracy: 0.9831\n",
      "Epoch 7/8\n",
      "168/168 [==============================] - 5s 29ms/step - loss: 0.0451 - accuracy: 0.9858\n",
      "Epoch 8/8\n",
      "168/168 [==============================] - 6s 35ms/step - loss: 0.0398 - accuracy: 0.9876\n",
      "263/263 [==============================] - 2s 6ms/step - loss: 0.0528 - accuracy: 0.9851\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.05282096192240715, 0.9851190447807312]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#infinity norm에 기반한 Adam의 변형인 Adamax가 궁금하여 사용해봤는데 결과가 그리 좋지 못하였다. \n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(512, input_shape = (784, ),activation = 'relu', kernel_initializer='he_uniform'), \n",
    "    keras.layers.BatchNormalization(), \n",
    "    keras.layers.Dropout(0.3),\n",
    "    keras.layers.Dense(512,activation = 'relu',kernel_initializer='he_uniform'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dropout(0.3),\n",
    "    keras.layers.Dense(10, activation = 'softmax', kernel_initializer='he_uniform')                         \n",
    "])\n",
    "    \n",
    "\n",
    "model.compile(optimizer='adamax',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, epochs=8, batch_size=200) \n",
    " \n",
    "model.evaluate(X_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* RMSProp : Adagrad에서 학습률이 급격하게 감소하는 문제를 해결하기 위한 기법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "168/168 [==============================] - 7s 40ms/step - loss: 0.2109 - accuracy: 0.9367\n",
      "Epoch 2/8\n",
      "168/168 [==============================] - 7s 39ms/step - loss: 0.0793 - accuracy: 0.9761\n",
      "Epoch 3/8\n",
      "168/168 [==============================] - 7s 41ms/step - loss: 0.0490 - accuracy: 0.9849\n",
      "Epoch 4/8\n",
      "168/168 [==============================] - 7s 39ms/step - loss: 0.0387 - accuracy: 0.9879\n",
      "Epoch 5/8\n",
      "168/168 [==============================] - 8s 46ms/step - loss: 0.0265 - accuracy: 0.9913\n",
      "Epoch 6/8\n",
      "168/168 [==============================] - 7s 39ms/step - loss: 0.0221 - accuracy: 0.9933\n",
      "Epoch 7/8\n",
      "168/168 [==============================] - 6s 38ms/step - loss: 0.0196 - accuracy: 0.9937\n",
      "Epoch 8/8\n",
      "168/168 [==============================] - 7s 40ms/step - loss: 0.0156 - accuracy: 0.9954\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 0.0487 - accuracy: 0.9892\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.04871207848191261, 0.9891666769981384]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(512, input_shape = (784, ),activation = 'relu', kernel_initializer='he_uniform'), \n",
    "    keras.layers.BatchNormalization(), \n",
    "    keras.layers.Dropout(0.3),\n",
    "    keras.layers.Dense(512,activation = 'relu',kernel_initializer='he_uniform'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dropout(0.3),\n",
    "    keras.layers.Dense(10, activation = 'softmax', kernel_initializer='he_uniform')                         \n",
    "])\n",
    "    \n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, epochs=8, batch_size=200) \n",
    " \n",
    "model.evaluate(X_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* dropout과 batchnormalization은 둘중에 하나만 써야하는 건줄 알았는데 같이 쓰니까 성능이 좋게나오는것 같다! 지금까지 한것중에 가장 좋은 성능이 나왔다.\n",
    "* 리더보드 제출했을때 결과가 0.98777이 나왔다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 이제부터 제일 성능이 잘나온 모델을 가지고 더 높이기 위해서 batch_size나 layer등을 바꿔볼 것이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "66/66 [==============================] - 6s 89ms/step - loss: 0.2635 - accuracy: 0.9207\n",
      "Epoch 2/8\n",
      "66/66 [==============================] - 5s 81ms/step - loss: 0.0883 - accuracy: 0.9723\n",
      "Epoch 3/8\n",
      "66/66 [==============================] - 6s 88ms/step - loss: 0.0558 - accuracy: 0.9831\n",
      "Epoch 4/8\n",
      "66/66 [==============================] - 6s 83ms/step - loss: 0.0397 - accuracy: 0.9879\n",
      "Epoch 5/8\n",
      "66/66 [==============================] - 6s 89ms/step - loss: 0.0278 - accuracy: 0.9913\n",
      "Epoch 6/8\n",
      "66/66 [==============================] - 6s 89ms/step - loss: 0.0234 - accuracy: 0.9926\n",
      "Epoch 7/8\n",
      "66/66 [==============================] - 5s 82ms/step - loss: 0.0166 - accuracy: 0.9945\n",
      "Epoch 8/8\n",
      "66/66 [==============================] - 5s 83ms/step - loss: 0.0136 - accuracy: 0.9958\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 0.0521 - accuracy: 0.9862\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.052064232528209686, 0.9861904978752136]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(512, input_shape = (784, ),activation = 'relu', kernel_initializer='he_uniform'), \n",
    "    keras.layers.BatchNormalization(), \n",
    "    keras.layers.Dropout(0.3),\n",
    "    keras.layers.Dense(512,activation = 'relu',kernel_initializer='he_uniform'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dropout(0.3),\n",
    "    keras.layers.Dense(10, activation = 'softmax', kernel_initializer='he_uniform')                         \n",
    "])\n",
    "    \n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, epochs=8, batch_size=512) #batch_size를 늘려보았더니 200일떄보다 성능이 떨어졌다.\n",
    " \n",
    "model.evaluate(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.3165 - accuracy: 0.9021\n",
      "Epoch 2/8\n",
      "168/168 [==============================] - 3s 16ms/step - loss: 0.1202 - accuracy: 0.9632 0s - l\n",
      "Epoch 3/8\n",
      "168/168 [==============================] - 2s 14ms/step - loss: 0.0871 - accuracy: 0.9739\n",
      "Epoch 4/8\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 0.0681 - accuracy: 0.9788\n",
      "Epoch 5/8\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.0557 - accuracy: 0.9820\n",
      "Epoch 6/8\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.0464 - accuracy: 0.9849\n",
      "Epoch 7/8\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 0.0423 - accuracy: 0.9860 0s - loss: 0.0419 \n",
      "Epoch 8/8\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.0376 - accuracy: 0.9874\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 0.0504 - accuracy: 0.9858: 0s - loss: 0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.05038708820939064, 0.9858333468437195]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#layer수를 이것저것 변경해보아도 성능이 별로 좋아지지 않았다. #128,256,512\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(128, input_shape = (784, ),activation = 'relu', kernel_initializer='he_uniform'), \n",
    "    keras.layers.BatchNormalization(), \n",
    "    keras.layers.Dropout(0.3),\n",
    "    keras.layers.Dense(512,activation = 'relu',kernel_initializer='he_uniform'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dropout(0.3),\n",
    "    keras.layers.Dense(10, activation = 'softmax', kernel_initializer='he_uniform')                         \n",
    "])\n",
    "    \n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, epochs=8, batch_size=200) #batch_size를 위처럼 늘이고 줄여보니 200일떄가 가장 좋았다. \n",
    " \n",
    "model.evaluate(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "168/168 [==============================] - 9s 56ms/step - loss: 0.2431 - accuracy: 0.9255\n",
      "Epoch 2/8\n",
      "168/168 [==============================] - 9s 54ms/step - loss: 0.0940 - accuracy: 0.9712\n",
      "Epoch 3/8\n",
      "168/168 [==============================] - 9s 54ms/step - loss: 0.0611 - accuracy: 0.9806\n",
      "Epoch 4/8\n",
      "168/168 [==============================] - 9s 56ms/step - loss: 0.0469 - accuracy: 0.9848\n",
      "Epoch 5/8\n",
      "168/168 [==============================] - 9s 56ms/step - loss: 0.0368 - accuracy: 0.9886\n",
      "Epoch 6/8\n",
      "168/168 [==============================] - 9s 55ms/step - loss: 0.0298 - accuracy: 0.9906\n",
      "Epoch 7/8\n",
      "168/168 [==============================] - 10s 57ms/step - loss: 0.0252 - accuracy: 0.9920\n",
      "Epoch 8/8\n",
      "168/168 [==============================] - 12s 69ms/step - loss: 0.0213 - accuracy: 0.9932\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 0.0497 - accuracy: 0.9882\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.04971737787127495, 0.9882143139839172]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#3-Layer로 늘려보았다. -- 비슷비슷한거같다.\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(512, input_shape = (784, ),activation = 'relu', kernel_initializer='he_uniform'), \n",
    "    keras.layers.BatchNormalization(), \n",
    "    keras.layers.Dropout(0.3),\n",
    "    keras.layers.Dense(512,activation = 'relu',kernel_initializer='he_uniform'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dropout(0.3),\n",
    "    keras.layers.Dense(512,activation = 'relu',kernel_initializer='he_uniform'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dropout(0.3),\n",
    "    keras.layers.Dense(10, activation = 'softmax', kernel_initializer='he_uniform')                         \n",
    "])\n",
    "    \n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, epochs=8, batch_size=200) \n",
    " \n",
    "model.evaluate(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "168/168 [==============================] - 2s 10ms/step - loss: 0.4346 - accuracy: 0.8638\n",
      "Epoch 2/8\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 0.1531 - accuracy: 0.9530\n",
      "Epoch 3/8\n",
      "168/168 [==============================] - 2s 14ms/step - loss: 0.1116 - accuracy: 0.9656\n",
      "Epoch 4/8\n",
      "168/168 [==============================] - 2s 11ms/step - loss: 0.0904 - accuracy: 0.9728\n",
      "Epoch 5/8\n",
      "168/168 [==============================] - 2s 11ms/step - loss: 0.0765 - accuracy: 0.9762\n",
      "Epoch 6/8\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 0.0656 - accuracy: 0.9799\n",
      "Epoch 7/8\n",
      "168/168 [==============================] - 3s 18ms/step - loss: 0.0569 - accuracy: 0.9823 \n",
      "Epoch 8/8\n",
      "168/168 [==============================] - 2s 14ms/step - loss: 0.0525 - accuracy: 0.9839 1s -\n",
      "263/263 [==============================] - 1s 2ms/step - loss: 0.0547 - accuracy: 0.9851\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.05470075458288193, 0.9851190447807312]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#노드개수를 이런식으로 계속바꾸어봤지만 전보다 나아지진 않았다.-1 \n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(128, input_shape = (784, ),activation = 'relu', kernel_initializer='he_uniform'), \n",
    "    keras.layers.BatchNormalization(), \n",
    "    keras.layers.Dropout(0.3),\n",
    "    keras.layers.Dense(128,activation = 'relu',kernel_initializer='he_uniform'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dropout(0.3),\n",
    "    keras.layers.Dense(256,activation = 'relu',kernel_initializer='he_uniform'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dropout(0.3),\n",
    "    keras.layers.Dense(10, activation = 'softmax', kernel_initializer='he_uniform')                         \n",
    "])\n",
    "    \n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, epochs=8, batch_size=200) \n",
    " \n",
    "model.evaluate(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "168/168 [==============================] - 4s 21ms/step - loss: 0.3491 - accuracy: 0.8926\n",
      "Epoch 2/8\n",
      "168/168 [==============================] - 4s 23ms/step - loss: 0.1300 - accuracy: 0.9597\n",
      "Epoch 3/8\n",
      "168/168 [==============================] - 3s 19ms/step - loss: 0.0953 - accuracy: 0.9701\n",
      "Epoch 4/8\n",
      "168/168 [==============================] - 4s 26ms/step - loss: 0.0779 - accuracy: 0.9753\n",
      "Epoch 5/8\n",
      "168/168 [==============================] - 3s 20ms/step - loss: 0.0667 - accuracy: 0.9799\n",
      "Epoch 6/8\n",
      "168/168 [==============================] - 4s 26ms/step - loss: 0.0583 - accuracy: 0.9817\n",
      "Epoch 7/8\n",
      "168/168 [==============================] - 4s 23ms/step - loss: 0.0478 - accuracy: 0.9851 0s - loss:\n",
      "Epoch 8/8\n",
      "168/168 [==============================] - 3s 19ms/step - loss: 0.0434 - accuracy: 0.9864\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 0.0502 - accuracy: 0.9863\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.050212983042001724, 0.9863095283508301]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#노드개수를 이런식으로 계속바꾸어봤지만 전보다 나아지진 않았다.-2\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(128, input_shape = (784, ),activation = 'relu', kernel_initializer='he_uniform'), \n",
    "    keras.layers.BatchNormalization(), \n",
    "    keras.layers.Dropout(0.3),\n",
    "    keras.layers.Dense(512,activation = 'relu',kernel_initializer='he_uniform'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dropout(0.3),\n",
    "    keras.layers.Dense(256,activation = 'relu',kernel_initializer='he_uniform'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dropout(0.3),\n",
    "    keras.layers.Dense(10, activation = 'softmax', kernel_initializer='he_uniform')                         \n",
    "])\n",
    "    \n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, epochs=8, batch_size=200) \n",
    " \n",
    "model.evaluate(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "168/168 [==============================] - 8s 46ms/step - loss: 0.2031 - accuracy: 0.9405\n",
      "Epoch 2/10\n",
      "168/168 [==============================] - 8s 48ms/step - loss: 0.0763 - accuracy: 0.9774\n",
      "Epoch 3/10\n",
      "168/168 [==============================] - 8s 47ms/step - loss: 0.0495 - accuracy: 0.9844 0s -\n",
      "Epoch 4/10\n",
      "168/168 [==============================] - 8s 48ms/step - loss: 0.0341 - accuracy: 0.9893\n",
      "Epoch 5/10\n",
      "168/168 [==============================] - 9s 52ms/step - loss: 0.0259 - accuracy: 0.9921\n",
      "Epoch 6/10\n",
      "168/168 [==============================] - 9s 52ms/step - loss: 0.0224 - accuracy: 0.9928\n",
      "Epoch 7/10\n",
      "168/168 [==============================] - 7s 42ms/step - loss: 0.0190 - accuracy: 0.9938\n",
      "Epoch 8/10\n",
      "168/168 [==============================] - 6s 39ms/step - loss: 0.0159 - accuracy: 0.9948\n",
      "Epoch 9/10\n",
      "168/168 [==============================] - 7s 41ms/step - loss: 0.0130 - accuracy: 0.9959\n",
      "Epoch 10/10\n",
      "168/168 [==============================] - 7s 42ms/step - loss: 0.0108 - accuracy: 0.9963\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 0.0576 - accuracy: 0.9889\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.05760878324508667, 0.9889285564422607]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#3-layer가 그리좋지않은 성능을 보여서 다시 2-Layer를 사용하였다. \n",
    "#hidden layer의 가중치 초기화함수를 glorot_normal으로 바꿔보았다. -- 결과가 나쁘지않아서 캐글에 올려보았는데 0.98666이 나왔다\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(512, input_shape = (784, ),activation = 'relu', kernel_initializer='he_uniform'), \n",
    "    keras.layers.BatchNormalization(), \n",
    "    keras.layers.Dropout(0.3),\n",
    "    keras.layers.Dense(512,activation = 'relu',kernel_initializer='glorot_normal'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dropout(0.3),\n",
    "    keras.layers.Dense(10, activation = 'softmax', kernel_initializer='he_uniform')                         \n",
    "])\n",
    "    \n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=200) #에폭도 10으로 했을때가 8보다 결과가 좋았다\n",
    " \n",
    "model.evaluate(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "168/168 [==============================] - 8s 45ms/step - loss: 0.2224 - accuracy: 0.9341\n",
      "Epoch 2/10\n",
      "168/168 [==============================] - 7s 41ms/step - loss: 0.1079 - accuracy: 0.9657\n",
      "Epoch 3/10\n",
      "168/168 [==============================] - 6s 38ms/step - loss: 0.0789 - accuracy: 0.9754\n",
      "Epoch 4/10\n",
      "168/168 [==============================] - 7s 44ms/step - loss: 0.0629 - accuracy: 0.9803\n",
      "Epoch 5/10\n",
      "168/168 [==============================] - 7s 44ms/step - loss: 0.0503 - accuracy: 0.9847\n",
      "Epoch 6/10\n",
      "168/168 [==============================] - 7s 43ms/step - loss: 0.0444 - accuracy: 0.9860\n",
      "Epoch 7/10\n",
      "168/168 [==============================] - 7s 41ms/step - loss: 0.0372 - accuracy: 0.9879\n",
      "Epoch 8/10\n",
      "168/168 [==============================] - 7s 43ms/step - loss: 0.0314 - accuracy: 0.9902\n",
      "Epoch 9/10\n",
      "168/168 [==============================] - 8s 49ms/step - loss: 0.0286 - accuracy: 0.9912\n",
      "Epoch 10/10\n",
      "168/168 [==============================] - 6s 38ms/step - loss: 0.0253 - accuracy: 0.9914\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 0.0496 - accuracy: 0.9860\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.04962649568915367, 0.9859523773193359]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#활성화함수를 elu와 가중치초기화함수를 바꿔가며 시도해보았지만 별로 달라지지 않았다. \n",
    "from tensorflow.keras import optimizers\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(512, input_shape = (784, ),activation = 'elu', kernel_initializer='he_uniform'), \n",
    "    keras.layers.BatchNormalization(), \n",
    "    keras.layers.Dropout(0.3),\n",
    "    keras.layers.Dense(512,activation = 'elu',kernel_initializer='he_normal'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dropout(0.3),\n",
    "    keras.layers.Dense(10, activation = 'softmax', kernel_initializer='glorot_uniform')                         \n",
    "])\n",
    "    \n",
    "rmsprop = optimizers.RMSprop(lr = 0.001)\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=200) \n",
    " \n",
    "model.evaluate(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict_classes(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>57808</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4960</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35755</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15543</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>48968</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Id  Category\n",
       "0  57808         8\n",
       "1   4960         0\n",
       "2  35755         5\n",
       "3  15543         3\n",
       "4  48968         8"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_submission['Category'] = pd.Series(predictions)\n",
    "sample_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission.to_csv(\"submission.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 정리해보자면 제일높게 나온모델을 기반으로 여러가지를 바꾸어가며 시도했지만 결국 더좋은모델을 찾아내지 못했다..\n",
    "* 가장 놓은 성능을 보인 모델은 아래모델이며, train의 acc는 0.989, test의 acc는 0.98777이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model = keras.Sequential([<br>\n",
    "    keras.layers.Dense(512, input_shape = (784, ),activation = 'relu', kernel_initializer='he_uniform'), <br>\n",
    "    keras.layers.BatchNormalization(), <br>\n",
    "    keras.layers.Dropout(0.3),<br>\n",
    "    keras.layers.Dense(512,activation = 'relu',kernel_initializer='he_uniform'),<br>\n",
    "    keras.layers.BatchNormalization(),<br>\n",
    "    keras.layers.Dropout(0.3),<br>\n",
    "    keras.layers.Dense(10, activation = 'softmax', kernel_initializer='he_uniform')                         \n",
    "])\n",
    "    \n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, epochs=8, batch_size=200) \n",
    " \n",
    "model.evaluate(X_val, y_val)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
